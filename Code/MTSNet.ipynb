{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def3daf6-6a48-4546-9863-b07711334797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from gluonts.model.simple_feedforward import SimpleFeedForwardEstimator\n",
    "from gluonts.mx import Trainer\n",
    "from gluonts.mx import DistributionOutput\n",
    "from gluonts.mx.distribution import LaplaceOutput\n",
    "from gluonts.mx.distribution import GaussianOutput\n",
    "from gluonts.mx.distribution import LaplaceOutput\n",
    "from gluonts.mx.distribution import StudentTOutput\n",
    "from gluonts.mx import MeanScaler, NOPScaler\n",
    "from gluonts.mx import block\n",
    "from gluonts.mx.block.dropout import VariationalZoneoutCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35402ba3-e2b4-4019-afd5-03a71c04f673",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTSNet(gluon.HybridBlock):\n",
    "    def __init__(self,\n",
    "        prediction_length,\n",
    "        context_length,\n",
    "        distr_output,\n",
    "        num_cells,\n",
    "        num_sample_paths=100,\n",
    "        scaling=True,\n",
    "        **kwargs\n",
    "     ) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.prediction_length = prediction_length\n",
    "        self.context_length = context_length\n",
    "        self.distr_output = distr_output\n",
    "        self.num_cells = num_cells\n",
    "        self.num_sample_paths = num_sample_paths\n",
    "        self.proj_distr_args = distr_output.get_args_proj()\n",
    "        self.scaling = scaling\n",
    "\n",
    "        with self.name_scope():\n",
    "            self.rnn = mx.gluon.rnn.HybridSequentialRNNCell()\n",
    "            \n",
    "            cell = mx.gluon.rnn.LSTMCell(hidden_size=self.num_cells)\n",
    "            self.rnn.add(cell)\n",
    "            \n",
    "            cell = mx.gluon.rnn.LSTMCell(hidden_size=self.num_cells)\n",
    "            cell = mx.gluon.rnn.ResidualCell(cell)\n",
    "            self.rnn.add(cell)\n",
    "            \n",
    "            cell = mx.gluon.rnn.LSTMCell(hidden_size=self.num_cells)\n",
    "            cell= gluonts.mx.block.dropout.VariationalZoneoutCell(base_cell=cell,zoneout_outputs=0.2, zoneout_states=0.1)\n",
    "            self.rnn.add(cell)\n",
    "\n",
    "            if scaling:\n",
    "                self.scaler = MeanScaler(keepdims=True)\n",
    "            else:\n",
    "                self.scaler = NOPScaler(keepdims=True)        \n",
    "                \n",
    "    def compute_scale(self, past_target, past_observed_values):\n",
    "        _, scale = self.scaler(\n",
    "            past_target.slice_axis(\n",
    "                axis=1, begin=-self.context_length, end=None\n",
    "            ),\n",
    "            past_observed_values.slice_axis(\n",
    "                axis=1, begin=-self.context_length, end=None\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return scale\n",
    "\n",
    "    def unroll_encoder(\n",
    "        self,\n",
    "        F,\n",
    "        past_target,\n",
    "        past_observed_values,\n",
    "        future_target=None,\n",
    "        future_observed_values=None\n",
    "    ):\n",
    "        if future_target is not None:  \n",
    "            target_in = F.concat(\n",
    "                past_target, future_target, dim=-1\n",
    "            ).slice_axis(\n",
    "                axis=1, begin=-(self.context_length + self.prediction_length + 1), end=-1\n",
    "            )\n",
    "            observed_values_in = F.concat(\n",
    "                past_observed_values, future_observed_values, dim=-1\n",
    "            ).slice_axis(\n",
    "                axis=1, begin=-(self.context_length + self.prediction_length + 1), end=-1\n",
    "            )\n",
    "            rnn_length = self.context_length + self.prediction_length\n",
    "        else:  # during inference\n",
    "            target_in = past_target.slice_axis(\n",
    "                axis=1, begin=-(self.context_length + 1), end=-1\n",
    "            )\n",
    "            observed_values_in = past_observed_values.slice_axis(\n",
    "                axis=1, begin=-(self.context_length + 1), end=-1\n",
    "            )\n",
    "            rnn_length = self.context_length\n",
    "\n",
    "        scale = self.compute_scale(target_in, observed_values_in)\n",
    "        target_in_scale = F.broadcast_div(target_in, scale)\n",
    "        net_output, states = self.rnn.unroll(\n",
    "            inputs=target_in_scale,\n",
    "            length=rnn_length,\n",
    "            layout=\"NTC\",\n",
    "            merge_outputs=True,\n",
    "        )\n",
    "\n",
    "        return net_output, states, scale\n",
    "\n",
    "\n",
    "class TrainMTSNet(MTSNet):\n",
    "    def hybrid_forward(\n",
    "        self,\n",
    "        F,\n",
    "        past_target,\n",
    "        future_target,\n",
    "        past_observed_values,\n",
    "        future_observed_values\n",
    "    ):\n",
    "        net_output, _, scale = self.unroll_encoder(\n",
    "            F, past_target, past_observed_values, future_target, future_observed_values\n",
    "        )\n",
    "        target_out = F.concat(\n",
    "            past_target, future_target, dim=-1\n",
    "        ).slice_axis(\n",
    "            axis=1, begin=-(self.context_length + self.prediction_length), end=None\n",
    "        )\n",
    "        # project to parameters of assumed distribution \n",
    "        distr_args = self.proj_distr_args(net_output)\n",
    "        \n",
    "        distr = self.distr_output.distribution(distr_args, scale=scale)\n",
    "\n",
    "        # negative log-likelihood\n",
    "        loss = distr.loss(target_out)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class PredMTSNet(TrainMTSNet):\n",
    "    def sample_decoder(self, F, past_target, states, scale):\n",
    "        repeated_states = [\n",
    "            s.repeat(repeats=self.num_sample_paths, axis=0)\n",
    "            for s in states\n",
    "        ]\n",
    "        repeated_scale = scale.repeat(repeats=self.num_sample_paths, axis=0)\n",
    "        decoder_input = past_target.slice_axis(\n",
    "            axis=1, begin=-1, end=None\n",
    "        ).repeat(\n",
    "            repeats=self.num_sample_paths, axis=0\n",
    "        )\n",
    "\n",
    "        future_samples = []\n",
    "\n",
    "        for k in range(self.prediction_length):\n",
    "            rnn_outputs, repeated_states = self.rnn.unroll(\n",
    "                inputs=decoder_input,\n",
    "                length=1,\n",
    "                begin_state=repeated_states,\n",
    "                layout=\"NTC\",\n",
    "                merge_outputs=True,\n",
    "            )\n",
    "\n",
    "            distr_args = self.proj_distr_args(rnn_outputs)\n",
    "            distr = self.distr_output.distribution(distr_args, scale=repeated_scale)\n",
    "            new_samples = distr.sample()\n",
    "            future_samples.append(new_samples)\n",
    "            decoder_input = new_samples\n",
    "\n",
    "        samples = F.concat(*future_samples, dim=1)\n",
    "        return samples.reshape(shape=(-1, self.num_sample_paths, self.prediction_length))\n",
    "\n",
    "    def hybrid_forward(self, F, past_target, past_observed_values):\n",
    "        net_output, states, scale = self.unroll_encoder(\n",
    "            F, past_target, past_observed_values\n",
    "        )\n",
    "\n",
    "        samples = self.sample_decoder(F, past_target, states, scale)\n",
    "\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fe48d5-012c-4dec-9087-e13c0dc5a9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from mxnet.gluon import HybridBlock\n",
    "from gluonts.core.component import validated\n",
    "from gluonts.dataset.loader import TrainDataLoader\n",
    "from gluonts.model.predictor import Predictor\n",
    "from gluonts.mx import (\n",
    "    as_in_context,\n",
    "    batchify,\n",
    "    copy_parameters,\n",
    "    get_hybrid_forward_input_names,\n",
    "    GluonEstimator,\n",
    "    RepresentableBlockPredictor,\n",
    "    Trainer,\n",
    ")\n",
    "from gluonts.transform import (\n",
    "    ExpectedNumInstanceSampler,\n",
    "    Transformation,\n",
    "    InstanceSplitter,\n",
    "    TestSplitSampler,\n",
    "    SelectFields,\n",
    "    Chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99c5d3e-b6ae-4cc0-b848-885e20effb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTSNetEstimator(GluonEstimator):\n",
    "    @validated()\n",
    "    def __init__(\n",
    "        self,\n",
    "        prediction_length: int,\n",
    "        context_length: int,\n",
    "        freq: str,\n",
    "        distr_output: DistributionOutput,\n",
    "        num_cells: int,\n",
    "        num_sample_paths: int = 100,\n",
    "        scaling: bool = True,\n",
    "        batch_size: int = 6,\n",
    "        trainer: Trainer = Trainer()\n",
    "    ) -> None:\n",
    "        super().__init__(trainer=trainer, batch_size=batch_size)\n",
    "        self.prediction_length = prediction_length\n",
    "        self.context_length = context_length\n",
    "        self.freq = freq\n",
    "        self.distr_output = distr_output\n",
    "        self.num_cells = num_cells\n",
    "        self.num_sample_paths = num_sample_paths\n",
    "        self.scaling = scaling\n",
    "\n",
    "    def create_transformation(self):\n",
    "        # Feature transformation that the model uses for input.\n",
    "        return AddObservedValuesIndicator(\n",
    "            target_field=FieldName.TARGET,\n",
    "            output_field=FieldName.OBSERVED_VALUES,\n",
    "        )\n",
    "\n",
    "    def create_training_data_loader(self, dataset, **kwargs):\n",
    "        instance_splitter = InstanceSplitter(\n",
    "            target_field=FieldName.TARGET,\n",
    "            is_pad_field=FieldName.IS_PAD,\n",
    "            start_field=FieldName.START,\n",
    "            forecast_start_field=FieldName.FORECAST_START,\n",
    "            instance_sampler=ExpectedNumInstanceSampler(\n",
    "                num_instances=1,\n",
    "                min_future=self.prediction_length,\n",
    "            ),\n",
    "            past_length=self.context_length + 1,\n",
    "            future_length=self.prediction_length,\n",
    "            time_series_fields=[\n",
    "                FieldName.FEAT_DYNAMIC_REAL,\n",
    "                FieldName.OBSERVED_VALUES,\n",
    "            ],\n",
    "        )\n",
    "        input_names = get_hybrid_forward_input_names(TrainMTSNet)\n",
    "        return TrainDataLoader(\n",
    "            dataset=dataset,\n",
    "            transform=instance_splitter + SelectFields(input_names),\n",
    "            batch_size=self.batch_size,\n",
    "            stack_fn=partial(batchify, ctx=self.trainer.ctx, dtype=self.dtype),\n",
    "            decode_fn=partial(as_in_context, ctx=self.trainer.ctx),\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def create_training_network(self) -> TrainMTSNet:\n",
    "        return TrainMTSNet(\n",
    "            prediction_length=self.prediction_length,\n",
    "            context_length=self.context_length,\n",
    "            distr_output=self.distr_output,\n",
    "            num_cells=self.num_cells,\n",
    "            num_sample_paths=self.num_sample_paths,\n",
    "            scaling=self.scaling\n",
    "        )\n",
    "\n",
    "    def create_predictor(\n",
    "        self, transformation: Transformation, trained_network: HybridBlock\n",
    "    ) -> Predictor:\n",
    "        prediction_splitter = InstanceSplitter(\n",
    "            target_field=FieldName.TARGET,\n",
    "            is_pad_field=FieldName.IS_PAD,\n",
    "            start_field=FieldName.START,\n",
    "            forecast_start_field=FieldName.FORECAST_START,\n",
    "            instance_sampler=TestSplitSampler(),\n",
    "            past_length=self.context_length + 1,\n",
    "            future_length=self.prediction_length,\n",
    "            time_series_fields=[\n",
    "                FieldName.FEAT_DYNAMIC_REAL,\n",
    "                FieldName.OBSERVED_VALUES,\n",
    "            ],\n",
    "        )\n",
    "        prediction_network = PredMTSNet(\n",
    "            prediction_length=self.prediction_length,\n",
    "            context_length=self.context_length,\n",
    "            distr_output=self.distr_output,\n",
    "            num_cells=self.num_cells,\n",
    "            num_sample_paths=self.num_sample_paths,\n",
    "            scaling=self.scaling\n",
    "        )\n",
    "\n",
    "        copy_parameters(trained_network, prediction_network)\n",
    "\n",
    "        return RepresentableBlockPredictor(\n",
    "            input_transform=transformation + prediction_splitter,\n",
    "            prediction_net=prediction_network,\n",
    "            batch_size=self.trainer.batch_size,\n",
    "            freq=self.freq,\n",
    "            prediction_length=self.prediction_length,\n",
    "            ctx=self.trainer.ctx,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

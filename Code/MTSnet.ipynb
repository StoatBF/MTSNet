{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b9eb8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from gluonts.model.simple_feedforward import SimpleFeedForwardEstimator\n",
    "from gluonts.mx import Trainer\n",
    "from gluonts.mx import DistributionOutput\n",
    "from gluonts.mx.distribution import LaplaceOutput\n",
    "from gluonts.mx.distribution import GaussianOutput\n",
    "from gluonts.mx.distribution import LaplaceOutput\n",
    "from gluonts.mx.distribution import StudentTOutput\n",
    "from gluonts.mx import MeanScaler, NOPScaler\n",
    "from gluonts.mx import block\n",
    "from gluonts.mx.block.dropout import VariationalZoneoutCell\n",
    "import gluonts\n",
    "mx.random.seed(10)\n",
    "\n",
    "class PSRNN(gluon.HybridBlock):\n",
    "    def __init__(self,\n",
    "        prediction_length,\n",
    "        context_length,\n",
    "        distr_output,\n",
    "        num_cells,\n",
    "        num_sample_paths=100,\n",
    "        scaling=True,\n",
    "        **kwargs\n",
    "     ) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.prediction_length = prediction_length\n",
    "        self.context_length = context_length\n",
    "        self.distr_output = distr_output\n",
    "        self.num_cells = num_cells\n",
    "        self.num_sample_paths = num_sample_paths\n",
    "        self.proj_distr_args = distr_output.get_args_proj()\n",
    "        self.scaling = scaling\n",
    "\n",
    "        with self.name_scope():\n",
    "            self.rnn = mx.gluon.rnn.HybridSequentialRNNCell()\n",
    "            \n",
    "            cell = mx.gluon.rnn.LSTMCell(hidden_size=self.num_cells)\n",
    "            self.rnn.add(cell)\n",
    "            \n",
    "            cell = mx.gluon.rnn.LSTMCell(hidden_size=self.num_cells)\n",
    "            cell = mx.gluon.rnn.ResidualCell(cell)\n",
    "            self.rnn.add(cell)\n",
    "            \n",
    "            cell = mx.gluon.rnn.LSTMCell(hidden_size=self.num_cells)\n",
    "            cell= gluonts.mx.block.dropout.VariationalZoneoutCell(base_cell=cell,zoneout_outputs=0.2, zoneout_states=0.1)\n",
    "            self.rnn.add(cell)\n",
    "\n",
    "            if scaling:\n",
    "                self.scaler = MeanScaler(keepdims=True)\n",
    "            else:\n",
    "                self.scaler = NOPScaler(keepdims=True)        \n",
    "                \n",
    "    def compute_scale(self, past_target, past_observed_values):\n",
    "        _, scale = self.scaler(\n",
    "            past_target.slice_axis(\n",
    "                axis=1, begin=-self.context_length, end=None\n",
    "            ),\n",
    "            past_observed_values.slice_axis(\n",
    "                axis=1, begin=-self.context_length, end=None\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return scale\n",
    "\n",
    "    def unroll_encoder(\n",
    "        self,\n",
    "        F,\n",
    "        past_target,\n",
    "        past_observed_values,\n",
    "        future_target=None,\n",
    "        future_observed_values=None\n",
    "    ):\n",
    "        if future_target is not None:  \n",
    "            target_in = F.concat(\n",
    "                past_target, future_target, dim=-1\n",
    "            ).slice_axis(\n",
    "                axis=1, begin=-(self.context_length + self.prediction_length + 1), end=-1\n",
    "            )\n",
    "            observed_values_in = F.concat(\n",
    "                past_observed_values, future_observed_values, dim=-1\n",
    "            ).slice_axis(\n",
    "                axis=1, begin=-(self.context_length + self.prediction_length + 1), end=-1\n",
    "            )\n",
    "            rnn_length = self.context_length + self.prediction_length\n",
    "        else:  # during inference\n",
    "            target_in = past_target.slice_axis(\n",
    "                axis=1, begin=-(self.context_length + 1), end=-1\n",
    "            )\n",
    "            observed_values_in = past_observed_values.slice_axis(\n",
    "                axis=1, begin=-(self.context_length + 1), end=-1\n",
    "            )\n",
    "            rnn_length = self.context_length\n",
    "\n",
    "        scale = self.compute_scale(target_in, observed_values_in)\n",
    "        target_in_scale = F.broadcast_div(target_in, scale)\n",
    "        net_output, states = self.rnn.unroll(\n",
    "            inputs=target_in_scale,\n",
    "            length=rnn_length,\n",
    "            layout=\"NTC\",\n",
    "            merge_outputs=True,\n",
    "        )\n",
    "\n",
    "        return net_output, states, scale\n",
    "\n",
    "\n",
    "class TrainPSRNN(PSRNN):\n",
    "    def hybrid_forward(\n",
    "        self,\n",
    "        F,\n",
    "        past_target,\n",
    "        future_target,\n",
    "        past_observed_values,\n",
    "        future_observed_values\n",
    "    ):\n",
    "        net_output, _, scale = self.unroll_encoder(\n",
    "            F, past_target, past_observed_values, future_target, future_observed_values\n",
    "        )\n",
    "        target_out = F.concat(\n",
    "            past_target, future_target, dim=-1\n",
    "        ).slice_axis(\n",
    "            axis=1, begin=-(self.context_length + self.prediction_length), end=None\n",
    "        )\n",
    "        # project to parameters of assumed distribution \n",
    "        distr_args = self.proj_distr_args(net_output)\n",
    "        \n",
    "        distr = self.distr_output.distribution(distr_args, scale=scale)\n",
    "\n",
    "        # negative log-likelihood\n",
    "        loss = distr.loss(target_out)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class PredPSRNN(TrainPSRNN):\n",
    "    def sample_decoder(self, F, past_target, states, scale):\n",
    "        repeated_states = [\n",
    "            s.repeat(repeats=self.num_sample_paths, axis=0)\n",
    "            for s in states\n",
    "        ]\n",
    "        repeated_scale = scale.repeat(repeats=self.num_sample_paths, axis=0)\n",
    "        decoder_input = past_target.slice_axis(\n",
    "            axis=1, begin=-1, end=None\n",
    "        ).repeat(\n",
    "            repeats=self.num_sample_paths, axis=0\n",
    "        )\n",
    "\n",
    "        future_samples = []\n",
    "\n",
    "        for k in range(self.prediction_length):\n",
    "            rnn_outputs, repeated_states = self.rnn.unroll(\n",
    "                inputs=decoder_input,\n",
    "                length=1,\n",
    "                begin_state=repeated_states,\n",
    "                layout=\"NTC\",\n",
    "                merge_outputs=True,\n",
    "            )\n",
    "\n",
    "            distr_args = self.proj_distr_args(rnn_outputs)\n",
    "            distr = self.distr_output.distribution(distr_args, scale=repeated_scale)\n",
    "            new_samples = distr.sample()\n",
    "            future_samples.append(new_samples)\n",
    "            decoder_input = new_samples\n",
    "\n",
    "        samples = F.concat(*future_samples, dim=1)\n",
    "        return samples.reshape(shape=(-1, self.num_sample_paths, self.prediction_length))\n",
    "\n",
    "    def hybrid_forward(self, F, past_target, past_observed_values):\n",
    "        net_output, states, scale = self.unroll_encoder(\n",
    "            F, past_target, past_observed_values\n",
    "        )\n",
    "\n",
    "        samples = self.sample_decoder(F, past_target, states, scale)\n",
    "\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c24183",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
